---
title: 'Mineria de dades: PAC1'
author: "Autor: Ignasi Grau Muñoz"
date: "Octubre 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 05.584-PAC-header.html
  # pdf_document:
  #   highlight: zenburn
  #   toc: yes
  # word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*****
# Exemple guiat 
*****
No es tracta d'una pauta per a repetir sinó diferents exemples per donar-vos idees i inspirar-vos en la resolució.


*****
## Descripció de l'origen del conjunt de dades
*****

S'ha seleccionat un conjunt de dades del [National Highway Traffic Safety Administration](https://www.nhtsa.gov/) . El sistema d'informes d'anàlisi de mortalitat va ser creat als Estats Units per la National Highway Traffic Safety Administration per proporcionar una mesura global de la seguretat a les carreteres. (Font Wikipedia). Les dades pertany a l'any 2020. És tracta d'un conjunt de registres d'accidents que recullen dades significatives que els descriuen. Tots els accidents tenen alguna víctima mortal com a mínim. L'objectiu analític que tenim en ment és entendre que fa que un accident sigui greu i que vol dir que sigui greu. https://www.nhtsa.gov/crash-data-systems/fatality-analysis-reporting-system

## Anàlisi exploratòria

Volem fer una primera aproximació al conjunt de dades trobat i respondre a les preguntes més bàsiques. Quant registres té? Quantes variables? De quina tipologia són? Com es  distribueixen els valors de les variables? Hi ha problemes amb les dades, per exemple camps buits? Puc intuir ja el valor analític de les dades? Quines primeres conclusions puc extreure?

El primer pas per realitzar un anàlisi exploratòria és carregar el fitxer de dades.

```{r}
path = 'accident.CSV'
accidentData <- read.csv(path, row.names=NULL)
```

### Exploració del conjunt de dades

Verifiquem l'estructura del joc de dades principal. Veiem el nombre de columnes que tenim i exemples dels continguts de les files.
```{r}
structure = str(accidentData)
```

Veiem que tenim **81** variables i **35.766** registres

Revisem la descripció de les variables contingudes al fitxer i els tipus de variables es correspon al que hem carregat. Les organitzem lògicament per donar-los sentit i construïm un petit diccionari de dades utilitzant la documentació auxiliar.


+ **ST_CASE**  identificador d'accident

**FETS A ESTUDIAR**

+ **FATALS** morts 
+ **DRUNK_DR** conductors beguts
+ **VE_TOTAL** nombre de vehicles implicats en total 
+ **VE_FORMS** nombre de vehicles en moviment implicats
+ **PVH_INVL** nombre de vehicles estacionats implicats
+ **PEDS**     nombre de vianants implicats
+ **PERSONS**  nombre ocupants de vehicle implicats
+ **PERMVIT**  nombre conductors i ocupants implicats
+ **PERNOTMVIT** nombre vianants, ciclistes, a cavall... qualsevol cosa menys vehicle motoritzat

**DIMENSIÓ GEOGRÀFICA**

+ **STATE** codificació d'estat
+ **STATENAME** nom d'estat
+ **COUNTY** identificador de contat
+ **COUNTYNAME** comtat
+ **CITY** identificador de ciutat
+ **CITYNAME** ciutat
+ **NHS** 1 ha passat a autopista del NHS 0 no
+ **NHSNAME** TBD
+ **ROUTE**  identificador de ruta
+ **ROUTENAME** ruta
+ **TWAY_ID** via de transit (1982) 
+ **TWAY_ID2** via de transit (2004)
+ **RUR_URB** identificador de segment rural o urbà
+ **RUR_URBNAME** segment rural o urbà
+ **FUNC_SYS** classificació funcional segment
+ **FUNC_SYSNAME** TBD
+ **RD_OWNER** identificador propietari del segment     
+ **RD_OWNERNAME** propietari del segment 
+ **MILEPT** milla int
+ **MILEPTNAME** milla chr
+ **LATITUDE** latitud int    
+ **LATITUDENAME** latitud chr
+ **LONGITUD** longitud int
+ **LONGITUDNAME** longitud chr
+ **SP_JUR** codi jurisdicció
+ **SP_JURNAME** jurisdicció

**DIMENSIÓ TEMPORAL**

+ **DAY** dia         
+ **DAYNAME** dia repetit
+ **MONTH** mes    
+ **MONTHNAME** nom de mes
+ **YEAR** any
+ **DAY_WEEK** dia de la setmana    
+ **DAY_WEEKNAME** nom de dia de la setmana
+ **HOUR** hora
+ **HOURNAME** franja hora
+ **MINUTE** minut int
+ **MINUTENAME** minut chr

**DIMENSIÓ CONDICIONS ACCIDENT**

+ **HARM_EV** codi primer esdeveniment de l'accident que produeixi danys o lesions
+ **HARM_EVNAME** primer esdeveniment de l'accident que produeixi danys o lesions
+ **MAN_COLL** codi de posició dels vehicles 
+ **MAN_COLLNAME** posició dels vehicles
+ **RELJCT1** codi si hi ha àrea d'intercanvi
+ **RELJCT1NAME**  si hi ha àrea d'intercanvi
+ **RELJCT2** codi proximitat encreuament
+ **RELJCT2NAME** proximitat encreuament
+ **TYP_INT** codi tipus d'intersecció
+ **TYP_INTNAME** tipus d'intersecció
+ **WRK_ZONE** codi tipologia d'obres     
+ **WRK_ZONENAME** tipologia d'obres
+ **REL_ROAD**     codi ubicació vehicle a la via
+ **REL_ROADNAME** ubicació vehicle a la via
+ **LGT_COND**     codi condició lumínica
+ **LGT_CONDNAME** condició lumínica

**DIMENSIÓ METEOROLOGIA**

+ **WEATHER**     codi temps
+ **WEATHERNAME** : temps

**ALTRES**

+ **SCH_BUS** codi si vehicle escolar implicat
+ **SCH_BUSNAME** vehicle escolar implicat
+ **RAIL** codi si dins o a prop pas ferroviari
+ **RAILNAME**  si dins o a prop pas ferroviari

**DIMENSIÓ SERVEI EMERGENCIES**

+ **NOT_HOUR** hora notificació a emergències int
+ **NOT_HOURNAME** hora notificació a emergències franja 
+ **NOT_MIN** minut notificació a emergències int
+ **NOT_MINNAME** minut notificació a emergències chr
+ **ARR_HOUR** hora arribada emergències int
+ **ARR_HOURNAME** hora arribada emergències franja
+ **ARR_MIN** minut arribada emergències int
+ **ARR_MINNAME** minut arribada emergències franja 
+ **HOSP_HR** hora arribada hospital int
+ **HOSP_HRNAME** hora arribada hospital franja
+ **HOSP_MN** minut arribada hospital int
+ **HOSP_MNNAME** : minut arribada hospital franja

## Preprocessament i gestió de característiques

### Neteja

El següent pas serà la neteja de dades, mirant si hi ha valors buits o nulls. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
print('NA')
colSums(is.na(accidentData))
print('Blancs')
colSums(accidentData=="")
```

Veiem que no hi ha valors nuls a les dades. També verifiquem camps omplerts de espais en blanc. En aquest cas sí trobem el camp TWAY_ID2 amb 26.997 valors en blanc. Valorem no fer cap acció d'eliminar registres ja que aquest camp no l'utilitzarem.


Anem a crear histogrames i descriure els valors per veure les dades en general d'aquests atributs per fer una primera aproximació al contingut de les dades:

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
if(!require('xfun')) install.packages('xfun'); library('xfun')

summary(accidentData[c("FATALS","DRUNK_DR")])
#Crearem primer una llista per mostrar desprès les gràfiques en un sol grid 
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()

n = c("FATALS","DRUNK_DR")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Comptador d'ocurrències per variable") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)

```


Observacions: 

Nombre de morts: Tots els accidents recollits en aquestes dades reporten una mort com a mínim. Sent l'accident més greu amb vuit víctimes i veiem que la distribució s'acumula de forma molt evident en una mort per accident.

Conductors beguts involucrats a l'accident: Analitzarem amb més detall aquesta dada més endavant per derivar una nova dada: Accidents on l'alcohol està present o no. D'entrada la mitjana és de 0.26% d'accidents on intervé un conductor begut. La franja va d'un conductor a quatre com a màxim que apareixen en un accident amb víctimes mortals.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(accidentData[c("VE_TOTAL","VE_FORMS","PVH_INVL")])
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()
n = c("VE_TOTAL","VE_FORMS","PVH_INVL")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)

```

Observacions pel que fa als vehicles implicats. 

Nombre de vehicles implicats (VE_TOTAL) en total està a la franja de 1 fins 59 sent el valor màxim i una mitjana de 1,5. 
Nombre de vehicles en moviment implicats (VE_FORMS), el valor més habitual és 1 amb un valor màxim també de 59. Preveiem que hi ha un valor extrem que caldrà tractar per poder treure més informació d'aquesta variable.
Nombre de vehicles estacionats implicats (PHL_INVL): Pel que fa aquesta variable l'habitual és que no hi hagi vehicles estacionats pels incidents recollits en aquestes dades. Amb tot apareixen casos aïllats on fins i tot hi havia 10 cotxes estacionats.


```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(accidentData[c("PEDS","PERSONS","PERMVIT","PERNOTMVIT")])
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()
n = c("PEDS","PERSONS","PERMVIT","PERNOTMVIT")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)
```

Observacions pel que fa a les persones implicades en un accident.

El nombre de vianant implicats (PEDS) és molt baix sent coherent amb el tipus de via que s'estudia i on no és habitual que hi hagi gent caminant. Amb tot el valor com a mitjana de 0,22 i màxim de 8 obliga a investigar més aquesta dada.
(PERSONS) El nombre d'ocupants de vehicle implicats es situa com a mitjana en 2,1  (PERMVIT) El nombre conductors i ocupants de vehicles en circulació implicats amb valor de mitjana de 2,1. Aquestes dues variables recullen la mateixa informació però la quantifiquen de diferent manera. L'accident amb el major nombre d'ocupants és de 61 persones.  
Pel que nombre vianant, ciclistes, fins i tot persones en vehicles aparcats... qualsevol cosa menys vehicle circulant (PERNOTMVIT) veiem que augmenta una mica la mitjana respecte a vianant ja que entenen que s'inclouen més casos.

Anem a aprofundir una mica en el tema de la relació de l'alcohol en els conductors i el nombre d'accidents.

```{r}
accidentData$alcohol <- ifelse(accidentData$DRUNK_DR %in% c(0), 0, 1)
counts <- table(accidentData$alcohol)
barplot(prop.table(counts),col=c("green","red"), main="Accidents amb conductor begut", legend.text=c("No Alcohol","Sí Alcohol"),xlab ="Presencia Alcohol", ylab = "Percentatge",ylim=c(0,0.8) )
```

Veiem que percentualment a la gran majoria d'accidents, al voltant del 75% no hi ha presència d'alcohol en el conductor. El conductors que donen positiu estan al voltant d'un 22%. Hem cercat contrastar la dada amb altres països i estarien en un valor central on els valors extrems màxim per país superen el 50% i els mínims estan sobre el 10%

Observem ara com es distribueixen les morts per accident.
```{r}
df1 <- accidentData %>%
  group_by(accidentData$FATALS) %>%
  dplyr::summarise(counts = n())
df1

counts <- table(accidentData$FATALS)
barplot(prop.table(counts),col=("red"),ylim=c(0,0.99),main="Distribució de la mortalitat als accidents",xlab ="Nombre de morts", ylab = "Percentatge")
```

Veiem que la majoria d'accidents tenen com a mínim un mort. Anem ara estudiar relacionat mortalitat alcohol.
```{r}
counts <- table(accidentData$alcohol, accidentData$FATALS)
colors <- c("green", "red")
barplot(prop.table(counts), beside = TRUE, col = colors, 
        ylim = c(0, 1), axes = TRUE,
        xlab = "Nombre de morts",
        ylab = "Percentatge",
        main = "Accidents per morts i conductors positius en alcohol",
        legend = c("No Alcohol", "Alcohol"), 
        fill = colors)
```

```{r}
counts <- table(accidentData$FATALS, accidentData$alcohol)
barplot(prop.table(counts), main="Accidents per conductors positius en alcohol i nombre de morts",
  xlab="0 No alcohol 1 Alcohol", col=rainbow(8), ylab="Percentantge",                             
  legend = rownames(counts), beside=TRUE,ylim=c(0,0.8))
```


Provarem ara si hi ha relació entre l'estat on ha passat l'accident i el nombre de conductors beguts. Fitrem els cinc estats on hi ha més accidents.

```{r echo=TRUE, message=FALSE, warning=FALSE}
accidentDataST5=subset(accidentData, accidentData$STATENAME == "California" | accidentData$STATENAME == "Texas" | accidentData$STATENAME == "Florida" | accidentData$STATENAME == "Georgia" | accidentData$STATENAME == "North Carolina")
files=dim(accidentDataST5)[1]
ggplot(data=accidentDataST5[1:files,],aes(x=DRUNK_DR,fill=STATENAME))+geom_bar()+ggtitle("Relació entre les variables conductor begut i Estat")+labs(x="Nombre de conductors beguts implicats")
```

Com a reflexió aquest gràfic té que passar pel filtre de percentuar el nombre d'accidents per estat i la població de l'estat per no treure conclusions precipitades.

Vegem ara com en un mateix gràfic de freqüències podem treballar amb 3 variables: FATALS, STATENAME i WEATHERNAME.


```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = accidentDataST5[1:files,],aes(x=FATALS,fill=STATENAME))+geom_bar(position="fill")+facet_wrap(~WEATHERNAME)+ggtitle("Nombre de morts en accident per Estat i clima")+labs(x="Nombre de morts") 
```

Aquesta gràfica està bé com a mecànica de construcció però els resultats els posem en dubte. Està bé com a pas inicial però cal aprofundir molt més. 

Anem a cercar les correlacions en funció de les morts i unes variables triades que creiem poden ajudar a explicar l'augment de morts per accident:

**DRUNK_DR** conductors beguts
**VE_TOTAL** nombre vehicles implicats en total 
**VE_FORMS** nombre vehicles en moviment implicats
**PVH_INVL** nombre vehicles estacionats implicats
**PEDS**     nombre vianants implicats
**PERSONS**  nombre ocupants de vehicle implicats
**PERMVIT**  nombre conductors i ocupants implicats
**PERNOTMVIT** nombre vianants, ciclistes... qualsevol cosa menys vehicle motoritzat



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Utilitzem aquesta llibreria per fer servir la funcio multiplot()
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
#Crearem primer una llista per mostrar les gràfiques de correlacions
#Crearem una llista per mostrar els atributs que interessen.


n = c("DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT") 
accidentDataAux= accidentData %>% select(all_of(n))
histList2<- vector('list', ncol(accidentDataAux))
for(i in seq_along(accidentDataAux)){
  message(i)
histList2[[i]]<-local({
  i<-i
  col <-log(accidentDataAux[[i]])
  ggp<- ggplot(data = accidentDataAux, aes(x = accidentData$FATALS, y=col)) + 
    geom_point(color = "gray30") + geom_smooth(method = lm,color = "firebrick") + 
    theme_bw() + xlab("Morts") + ylab(names(accidentDataAux)[i])
  })

}
multiplot(plotlist = histList2, cols = 3)
```

Podem veure que:

+ De forma general qualsevol augment en les variables triades implica un augment de les morts al accident.

+ El factor que fa augmentar més el nombre de víctimes son les variables relacionades amb els vianants i passatgers dels cotxes involucrats a l'accident.

Utilitzem les columnes que ens interessa per fer la matriu i la visualitzarem utilitzant la funció corrplot.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT")
factors= accidentData %>% select(all_of(n))
res<-cor(factors)
corrplot(res,method="color",tl.col="black", tl.srt=30, order = "AOE", 
   number.cex=0.75,sig.level = 0.01, addCoef.col = "black")
```

No veiem que hi hagi una correlació negativa significativa entre cap variable i sí una molt bona correlació ja previsible entre els vianants implicats i persones involucrades a l'accident que no van en cotxe. (PEDS i PERNOTMVIT) El mateix podem observar pel que fa al nombre de conductors i ocupants implicats (PERMVIT) i el nombre de vehicles implicats en moviment (VE_FORMS) o el total de vehicles (VE_TOTAL). 

Anem a provar si hi ha una correlació entre l'hora del accident  i el nombre de morts.

```{R}
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
cor.test(x = accidentData$PERSONS, y = accidentData$FATALS, method = "kendall")
ggplot(data = accidentData, aes(x = PERSONS, y = log(FATALS))) + geom_point(color = "gray30") + geom_smooth(color = "firebrick") + theme_bw() +ggtitle("Correlació entre persones implicades a l'accident i nombre de morts")
```

De l'observació d'aquest gràfic podem concloure que efectivament el nombre de morts augmenta en funció de les persones implicades en un accident però que la correlació no és tan elevada ni continua com es podia preveure.

## Construcció de conjunt de dades final  

Si dues variables estan tan altament correlacionades que òbviament impartiran gairebé exactament la mateixa informació en un  model de regressió per exemple. Però, en incloure totes dues, en realitat estem debilitant el model. No estem afegint informació incremental. En lloc d'això, estem fent un model sorollós. No és una bona cosa.

Com hem vist abans tenim una correlació molt gran entre PEDS i PERNOTMVIT, per tant podríem eliminar la columna de vianants (PEDS) i deixar el total de vianants i altres reflectit a PERNOTMVIT.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# accidentData$PEDS<- NULL
str(accidentData)

```

### Codificació

Seguidament anem a assignar un 1 per accidents que es produeixen de matinada (01h a 06h a l'hivern) i un 0 per a la resta de franja horària, es a dir, anem a categoritzar la variable HOUR i així tindrem una variable numèrica que ens permetrà treballar millor en el futur, l'anomenarem matinada. Després l'utilitzarem per veure com es distribueixen els accidents en les dues franges horàries. Hem de tenir en compte que la hora inclou el codi 99 què vol dir que l'hora no està informada. Mirarem de filtrar els registres amb aquest valor per excloure'ls. 
```{r}

accidentDataAux=subset(accidentData, accidentData$HOUR <= 24)

accidentData$matinada <- NA
accidentData$matinada[accidentDataAux$HOUR >=1 & accidentDataAux$HOUR <= 6] <- 1
accidentData$matinada[accidentDataAux$HOUR ==0 | accidentDataAux$HOUR >6 ] <- 0

counts <- table(accidentData$matinada)
barplot(prop.table(counts),col=c("green","red"),legend.text=c("Resta del dia","Matinada"),ylim=c(0,1), main="Distribució d'accidents la matinada i resta del dia",xlab="0 Resta del dia 1 Matinada",ylab="Percentatge" )

```

### Discretització

Ara afegirem un camp nou a les dades. Aquest camps contindrà el valor de l'hora de l'accident discretitzada amb un mètode simple d'intervals d'igual amplitud.

```{r echo=TRUE, message=FALSE, warning=FALSE}

summary(accidentDataAux[,"HOUR"])
```

Discretitzem amb intervals. Els criteris de tall horaris estan agafats de la Web del Parlament de Catalunya.

```{r}
accidentDataAux["segment_horari"] <- cut(accidentDataAux$HOUR, breaks = c(0,4,11,14,18,22), labels = c("Matinada", "Matí", "Migdia", "Vespre","Nit"))
```

Observem les dades discretitzades i construïm un gràfic per analitzar com s'agrupen els accidents. 

```{r}
head(accidentDataAux$segment_horari)
```
```{r}
plot(accidentDataAux$segment_horari,main="Nombre d'accidents per segment horari",xlab="Segment horari", ylab="Quantitat",col = "ivory")
```

Ara anem a discretitzar la variable que conté el nombre de vehicles implicats en un accident (VE_TOTALS) ja que era una de les que las distancies entre els seus valors era molt gran: 

```{r}
# Farem servir funció discretize d'arules: This function implements several basic unsupervised methods to convert a continuous variable into a categorical variable (factor) using different binning strategies.
# https://cran.r-project.org/web/packages/arules/index.html
if (!require('arules')) install.packages('arules'); library('arules')
set.seed(2)
table(discretize(accidentData$VE_TOTAL, "cluster" ))
hist(accidentData$VE_TOTAL, main="Nombre d'accidents per vehicles implicats amb kmeans",xlab="Vehicles implicats", ylab="Quantitat",col = "ivory")
abline(v=discretize(accidentData$VE_TOTAL, method="cluster", onlycuts=TRUE),col="red")
```

Podem observar que sense passar cap argument i que l’algorisme triï el conjunt de particions es mostren tres clústers que agrupen els vehicles implicats en les franges esmentades. Podem assignar el propi clúster com una variable més al dataset per treballar-hi després.

```{r}
accidentData$VE_TOTAL_KM<- (discretize(accidentData$VE_TOTAL, "cluster" ))
head(accidentData$VE_TOTAL_KM)
```

### Normalització


Ara normalitzarem el nombre de morts pel màxim afegint un nou valor a les dades que contindrà el valor. 

```{r}
accidentData$FATALS_NM<- (accidentData$FATALS/max(accidentData[,"FATALS"]))
head(accidentData$FATALS_NM)

```
Suposem que ens cal normalitzar per la diferencia per ubicar entre 0 i 1 la variable del nombre de morts de l'accident donat que l'algorisme de mineria que utilitzarem així ho requereix. Observem la distribució de la variable original i les  generades.
```{r}

accidentData$FATALS_ND = (accidentData$FATALS-min(accidentData$FATALS))/(max(accidentData$FATALS)-min(accidentData$FATALS))

max(accidentData$FATALS)
min(accidentData$FATALS)
hist(accidentData$FATALS,xlab="Morts", col="ivory",ylab="Quantitat", main="Nombre de morts en accident")
hist(accidentData$FATALS_NM,xlab="Morts",ylab="Quantitat",col="ivory", main="Morts normalitzat pel màxim")
hist(accidentData$FATALS_ND,xlab="Morts",ylab="Quantitat", col="ivory", main="Morts normalitzat per la diferència")
```

A continuació anem a normalitzar les altres columnes per assegurar-nos que cada variable contribueix per igual al nostre anàlisis. 
```{r}
# Definim la funció de normalització
 nor <-function(x) { (x -min(x))/(max(x)-min(x))}
# Guardem un nou dataset normalitzat

accidentData$type<- NULL
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT")
accidentData<- accidentData %>% select(all_of(n))
accidentData_nor <- as.data.frame(lapply(accidentData, nor))

 head(accidentData_nor)
```

## Procés de PCA 

Tant l’ **anàlisi de components principals, principal component analysis (PCA) en anglès, com la descomposició de valors singulars, singular value decomposition (SVD) **en anglès, són tècniques que ens permeten treballar amb noves característiques anomenades components, que certament són independents entre si.
En realitat, aquestes dues tècniques ens permeten representar el joc de dades en un nou sistema de coordenades que anomenem components principals.
Aquest sistema està més ben adaptat a la distribució del joc de dades, de manera que recull millor la seva variabilitat.

Apliquem l'anàlisi de components principals al row data set per això comencem executant la funció **prcomp()**.
```{r}
pca.acc <- prcomp(accidentData_nor)
summary(pca.acc)
```

Com es pot observar la funció summary, ens torna la proporció de variància aplicada al conjunt total de cada atribut. Gràcies a això, l'atribut 1 explica el 0.452 de variabilitat del total de dades; en canvi, l'atribut 7 explica només el 0.00381.

A continuació es mostra un histograma per veure el pes de cada atribut sobre el conjunt total de dades:
```{r}
if (!require('factoextra')) install.packages('factoextra'); library('factoextra')
#Els valors propis corresponen a la quantitat de variació explicada per cada component principal (PC).
ev= get_eig(pca.acc)
ev
fviz_eig(pca.acc)
```

En aquest exercici es va decidir utilitzar el mètode de Kàiser per decidir quina de les variables obtingudes seran escollides. Aquest criteri mantindrà totes aquelles variables la variància de les quals sigui superior a 1. 
```{r}
# Calculem la variància dels components principals a partir de la desviació estàndard

var_acc <- pca.acc$sdev^2

var_acc
```

Amb els resultats obtinguts és molt complicat decidir quines són les components principals components a escollir. **Aquest fet podria estar causat per no haver escalat les dades prèviament.** Per tant, el següent pas és escalar les dades i tornar a calcular la variància per veure quines dades selecciones
```{r}
# Escalem les dades
acc_scale <- scale(accidentData_nor)
# Calculem les components principals
pca.acc_scale <- prcomp(acc_scale)
# Mostramos la varianza de dichas variables:
var_acc_scale <- pca.acc_scale$sdev^2
head(var_acc_scale)
```

Després d'analitzar la variància i aplicant el criteri de Kàiser ens quedarem amb les components principals 1,2,3 i 4 que són les superiors a 1. Aquest criteri té el problema de sobreestimar el nombre de factors, però malgrat això és el que aplicarem per analitzar els resultats.

Mostrem l'histograma de percentatge de variància explicat amb les dades escalades:
```{r}
fviz_eig(pca.acc_scale)
ev = get_eig(pca.acc_scale)
ev
```

Els valors propis es poden utilitzar per determinar el nombre de components principals a retenir després de la PCA (Kaiser 1961):

+ Un valor propi > 1 indica que els PCs representen més variància de la que representa una de les variables originals de les dades estandarditzades. Això s'utilitza habitualment com a punt de tall per al qual es conserven els PCs. Això només és cert quan les dades estan estandarditzades.

+ També podem limitar el nombre de components a aquest nombre que representa una determinada fracció de la variància total. Per exemple, si estem satisfets amb el 80% de la variància total explicada, fem servir el nombre de components per aconseguir-ho que són les 4 components principals vists abans.

Continuem amb l'anàlisi dels components principals. Després d'aplicar el mètode Kàiser s'han seleccionat els 4 components principals.

```{r}
var <- get_pca_var(pca.acc_scale)
var
```

Els components de get_pca_var() es poden utilitzar en el diagrama de variables de la següent manera:

+ **var$coord**: coordenades de variables per crear un diagrama de dispersió.
+ **var$cos2**: representa la qualitat de representació de les variables al mapa de factors. Es calcula com les coordenades al quadrat: var.cos2 = var.coord * var.coord.
+ **var$contrib**: conté les contribucions (en percentatge) de les variables als components principals. La contribució d'una variable (var) a un determinat component principal és (en percentatge): (var.cos2 * 100) / (cos2 total del component).

```{r}
#Utilitzem els 4 components principals trobats abans
head(var$coord[,1:4],11)
```

### Qualitat de representació
La qualitat de representació de les variables en el mapa de factors s'anomena cos2 (cosinus quadrat, coordenades quadrades). Podem accedir al cos2 de la següent manera:

```{r}
head(var$cos2[,1:4],11)
```
```{r}
corrplot(var$cos2[,1:4], is.corr=FALSE)
```

També és possible crear un diagrama de barres de variables cos2 mitjançant la funció fviz_cos2():
```{r}
fviz_cos2(pca.acc_scale, choice = "var", axes = 1:2)
```

+ Un cos2 elevat indica una bona representació de la variable en el component principal. En aquest cas, la variable es col·loca prop de la circumferència del cercle de correlació.

+ Un cos2 baix indica que la variable no està perfectament representada pels PC. En aquest cas, la variable està a prop del centre del cercle.

Per a una variable donada, la suma del cos2 de tots els components principals és igual a un.

Si una variable està perfectament representada per només dos components principals (Dim.1 i Dim.2), la suma del cos2 en aquests dos PCs és igual a un. En aquest cas les variables es col·locaran en el cercle de correlacions.

Per a algunes de les variables, poden ser necessaris més de 2 components per representar perfectament les dades. En aquest cas les variables es situen dins del cercle de correlacions.

En resum:

+ Els valors de cos2 s'utilitzen per estimar la qualitat de la representació
+ Com més propera estigui una variable al cercle de correlacions, millor serà la seva representació al mapa de factors (i més important és interpretar aquests components)
+ Les variables que estan properes al centre de la trama són menys importants per als primers components.
```{r}
fviz_pca_var(pca.acc_scale,
             col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     
             )
```

###  Contribució

Les contribucions de les variables en la comptabilització de la variabilitat d'un determinat component principal s'expressen en percentatge.

Les variables que estan correlacionades amb PC1 (és a dir, Dim.1) i PC2 (és a dir, Dim.2) són les més importants per explicar la variabilitat en el conjunt de dades.

Les variables que no estan correlacionades amb cap PC o amb les darreres dimensions són variables amb una contribució baixa i es poden eliminar per simplificar l'anàlisi global.

La contribució de les variables es pot extreure de la següent manera:
```{r}
head(var$contrib[,1:4],11)
```

Quan més gran sigui el valor de la contribució, més aportació de la variable hi haurà al component.

```{r}
corrplot(var$contrib[,1:4], is.corr=FALSE)
``` 

Les variables més importants (que més contribueixen) es poden ressaltar a la gràfica de correlació de la següent manera:
```{r}
fviz_pca_var(pca.acc_scale, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
             )
``` 

Les variables correlacionades positives apunten al mateix costat de la trama. Les variables correlacionades negatives apunten a costats oposats del gràfic. Per exemple, veiem que les persones involucrades en un accident (PVH_INVL) i conductor begut (DRUNK_DR) apunten direccions oposades per tan no estan gens correlaciones, a més ho hem vist abans ja que tenen un coeficient de correlació de -0.01.

S' observa que la variable que més aporta a les components principals són **PEDS i PERNOTMVIT per un costat  i VE_TOTAL, VE_FORMS, PERSONS i PERMVIT**. Això és degut al fet que estan correlacionades. En concret pel diagrama de correlació d' abans que PEDS esta molt bé correlacionada amb PERNOTMVIT. D' altra banda VE_TOTAL, VE_FORMS, PERSONS i PERMVIT estan també força correlacionades. La correlació de FATALS amb aquest grup de variables no és elevada però apunta en la mateixa direcció.

Podrien ara refer els components excloent les variables que no aporten informació. Un cop refet aquestes noves variables substitueixen a les originals que les formen i es podrien utilitzar per exemple com un indicador de gravetat d'accident ja que inclou vehicle en moviment, aturat, vianants, conductors i d'altres implicats en una sola variable. 

## Interpretació dels resultats

Las dades estudiades contemplen accidents de tràfic amb víctimes a les xarxes d’autopistes als EUUU a llarg del 2020. Tots els registres tenen un identificador únic d’accident i una sèrie de fets principals com nombre de morts, nombre de conductors beguts, vehicles i persones ¡ persones implicades. Hem d’afegir altres variables que els caracteritzen agrupades de ubicació geogràfica, temporal, condicions específiques de l’accident, meteorològiques, la intervenció del serveis d’emergències  i d’altres factors.

Revisades les dades semblen ben informades  sense  Les dades estan força netes i ben documentades. No plantegen greus problemes de camps amb valors nuls o buits i tenen força potencial per generar nous indicadors a partir de les dades.

Podem afirmar que al llarg del 2020 a les autopistes d'EEUU van succeir 35.766 accidents on van perdre la vida 38.824 persones. Pretenien extreure relacions entre la presencia d'alcohol en els conductors i el nombre d'accidents però les conclusions no son clares. Les relacions més obvies però comprovades són el increment de morts en funció de l’increment del nombre de vehicles, passatgers i vianants implicats.  

Caldria aprofundir molt més. Sí que podem perfilar com són els accidents típics pel que fa al nombre de vehicles i persones, conductors o vianants implicats.

El més habitual és un mort per accident incrementant-se aquest valor en funció de les variables relacionades. Els conductors beguts apareixen en un de cada quatre accidents mortals aproximadament.  Els vehicles implicats en els accident són típicament un en aquests tipus d’accident podent-se incrementar a dos en els casos més típics.  El nombre de vianants implicats és relativament baix donat el tipus de via que estem estudiant.

Pel que fa al consum d’alcohol amb el grau de profunditat estudiat no s’observa un estat on la proporcionalitats del nombre de conductor amb presència d’alcohol  sigui superior.

Estudiant el nombre de morts en accident en relació a l’Estat on ha succeït i la condició climàtica veiem necessari aprofundir amb tècniques per exemple d’agregació ver veure com s’agrupen i poder obtenir un perfil.  

S’ha estudiat la franja horària de la matinada per veure si acumulava un major nombre d’accidents no sent així. Sembla que el nombre d’accidents manté també proporcionalitat. S’ha estudiant el nombre d’accidents per segment horari amb una discretització fixada en interval arbitraris. La major presencia d’accidents en horari de matí i vespre (anar i tornar a la feina) fa pensar en que queda pendent estudiar donat el tipus de via la distribució horària dels accidents dilluns a divendres respecte als caps de setmana i festius per veure si hi ha hores on s’acumulen més accidents mortals. 

Finalment amb la tècnica dels components principals hem generat una nova variable que combina d’altres variables amb una correlació inicial que es podria considerar com índex de gravetat de l’accident.



*****
# Exercici 1
*****


Proposa un projecte complet de mineria de dades. L'organització de la resposta ha de coincidir en les fases típiques del cicle de vida d'un projecte de mineria de dades. **No cal fer les tasques de la fase**. Per a cada fase indica quin és el objectiu de la fase i el producte que s'obtindrà. Utilitza exemples de quines i com podrien ser les tasques. Si hi ha alguna característica que fa diferent el cicle de vida d'un projecte de mineria respecte a d'altres projectes indica-ho.


> RESPOSTA

La primera fase d’un projecte de mineria de dades es la definició de l’objectiu al que es vol arribar tenint en compte les dades disponibles. En el cas de les dades proporcionades en aquesta activitat, l’objectiu final podria ser identificar els factors clau que contribueixen als accidents de tràfic en una àrea específica per millorar la seguretat viària. En aquest cas, la tasca principal seria analitzar les dades disponibles per identificar patrons, com la relació entre condicions meteorològiques, hora del dia, tipus de vehicle, velocitat, etc., i la probabilitat d'ocurrència d'accidents de cotxe.

El mètode més adequat dependrà de la naturalesa de les dades i de l'objectiu específic. En aquest escenari, es podrien utilitzar diversos mètodes com ara anàlisi de regressió o anàlisi de clùsters. En el nostre exeple un model de clustering és més convenient per descobrir patrons ocults, mentres que la regresió és més útil per modelar relacions matemàtiques. Per la naturalesa de les nostres dades el clustering és més convenitn

La segona fase és la selecció de les dades més rellevants. Aquesta fase implica identificar les variables que tenen una influència significativa en la freqüència o gravetat dels accidents de tràfic. Això podria incloure factors com: l’ubicació geogràfica, les condicions meteorològiques, factors humans o els factors de la carretera com el tipus de via.
La tercera fase d’un projecte de mineria de dades seria la preparació de les dades de cara a assegurar que siguin vàlides i es trobin en condicions de ser emprades pel mètode seleccionat. Dins d’aquesta fase hi ha varies tasques.	

Neteja de les dades: Aquesta és una tasca fonamental que implica la identificació i eliminació d'errors comuns com dades en blanc, valors atípics o valors inconsistents. Per exemple, s'han de detectar i eliminar registres de dades amb informació incompleta o amb valors impossibles, com velocitats de vehicles extremadament altes o baixes que no siguin realistes. 
Integració de les dades: Si estàs treballant amb múltiples conjunts de dades de diferents fonts, hauràs d'integrar-los de manera coherent, encara que no és el nostre cas. Això implica garantir que les diferents fonts de dades segueixin el mateix format i que els camps clau es corresponguin adequadament. Per exemple, assegurar-se que la informació sobre els vehicles involucrats en els accidents es correspongui amb la informació dels conductors i les condicions de la carretera. 

Transformació de les dades: A vegades, és necessari transformar les dades per aconseguir una millor comprensió o per facilitar l'anàlisi. Això pot implicar normalitzar dades com la velocitat o el pes dels vehicles, convertir les dades temporals a un format estàndard o categoritzar les variables numèriques en intervals per a un millor anàlisi. 
Selecció de mostres representatives: Si el conjunt de dades és molt gran, pot ser útil treballar amb una mostra representativa per a l'anàlisi inicial. Això pot accelerar el procés d'anàlisi i proporcionar una visió general del conjunt de dades sense necessitat de processar totes les dades al mateix temps.

Gestió de valors faltants: És crucial tenir cura dels valors faltants de manera adequada per evitar que afectin l'anàlisi. Això pot incloure la imputació de valors faltants basada en algoritmes de predicció o la eliminació de les observacions amb valors faltants si no són significatives per a l'anàlisi. 

Comprovació de la coherència i la cohesió: És essencial assegurar-se que les dades siguin coherents i cohesives, especialment si provenen de diverses fonts. Això implica assegurar-se que no hi hagi contradictions en els registres de dades i que tota la informació s'ajusti lògicament.

La següent fase es mineria de dades pròpiament dita, desenvolupar el model seleccionat prèviament per a l’anàlisi. Durant aquesta fase, és crucial ajustar els paràmetres del model i avaluar-ne el rendiment utilitzant mètriques apropiades per a l'anàlisi específica que s'està duent a terme. Això ajudarà a garantir la precisió i la fiabilitat dels resultats del model, sent essencial per a la presa de decisions i la implementació d'accions efectives per millorar la seguretat viària.

L’interpretació del model obtingut a partir de les dades és la següent fase del projecte. És essencial comprendre les conclusions i implicacions del model per a la seguretat viària. Això pot conduir a una revisió de les fases anteriors del projecte de mineria de dades per a una millor comprensió dels resultats i la presa de decisions més informada. Algunes possiblees accions en aquesta fase serian la revisió de les dades, l’ajust del model i la reavaluació dels objectius del projecte.

La interpretació adequada del model obtingut és crucial per a una presa de decisions efectiva i per a la implementació de mesures de millora de la seguretat viària. Això pot implicar ajustos i revisions de diverses fases anteriors per garantir que el projecte de mineria de dades proporcioni resultats significatius i útils per a l'objectiu final.

L’integració dels resultats de la mineria de dades en el sistema de tractament de la informació és l’última fase del projecte i una etapa crítica per assegurar que els beneficis dels resultats es tradueixin en accions concretes i mesurables. Aquest procés també implica la vigilància continua del rendiment del model i la implementació d'un procés de mineria de dades nou en cas que es detectin canvis significatius a l'entorn o un envelliment del model. En aquesta fase hi ha varies tasques a realitzar: integració dels resultats, observació del rendiment i detecció de canvis en l’entorn.

*****
# Exercici 2
*****
A partir del joc de dades utilitzat a l'exemple de la PAC, realitza les tasques prèvies a la generació d’un model de mineria de dades explicades en els mòduls  "El procés de mineria de dades" i "Preprocessat de les dades i gestió de característiques". Pots utilitzar de referència l'exemple però procura canviar l'enfocament i analitzar les dades en funció de les diferent dimensions que presenten les dades. Opcionalment i valorable es poden afegir a l'estudi de dades d'altres anys per a realitzar comparacions temporals (https://www.nhtsa.gov/file-downloads?p=nhtsa/downloads/FARS/) o afegir altres fets a estudiar relacionats, per exemple el consum de drogues en els accidents (https://static.nhtsa.gov/nhtsa/downloads/FARS/2020/National/FARS2020NationalCSV.zip)

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Carreguem el joc de dades
knitr::opts_chunk$set(echo = TRUE)
```
```{r}
path = 'accident.CSV'
accidentData <- read.csv(path, row.names=NULL)
```
# Redacta aquí el codi R per a l'estudi del joc de dades
```{r}
# Mirar l'estructura i la distribució de totes les variables
structure = str(accidentData)
summary = summary(accidentData)
print(summary)
```
```{r}
# Primer mirarem els valors buits i els valors en blanc
print('NA')
colSums(is.na(accidentData))
print('Blancs')
colSums(accidentData=="")


# En aquest dataset hi ha molta informació repetida, hi ha moltes variables duplicades. Primer en una versió de chars i despés en una versió quantificada en números, per analitzar aquestes dades ens quedarem amb la versió quantificada i borrarem l'altre.
# En el cas de valors en blanc, també eliminarem el camp, al ser un camp identificador no aporta res a l'estudi.

info_a_eliminar <- c("ST_CASE","STATENAME","CITYNAME","MONTHNAME","DAY_WEEKNAME","HOURNAME","MINUTENAME","ROUTENAME","ARR_HOURNAME","NOT_MINNAME","WEATHERNAME","COUNTYNAME",
                     "RUR_URBNAME","RD_OWNERNAME","MAN_COLLNAME","HARM_EVNAME","SP_JURNAME","MILEPTNAME","FUNC_SYSNAME","RELJCT1NAME",
                     "RELJCT2NAME","TYP_INTNAME","WORK_ZONENAME","REL_ROADNAME","LGT_CONDNAME","SCH_BUSNAME","RAILNAME","TWAY_ID2")
accidentData <- accidentData[, !(names(accidentData) %in% info_a_eliminar)]
```
```{r}
# Creem una nova variable que serà el ratio de mort per persona involucrada a l'accident

accidentData$PERSONES_TOTALS <- accidentData$PERMVIT + accidentData$PERNOTMVIT
accidentData$MORTALITAT <- accidentData$FATALS/accidentData$PERSONES_TOTALS

# La variable resultant es continua, i al ser un ratió el seu valor ja esta normalitzat. Ara procedirem a discretitzar la variable per facilitar els càlculs i la comprenció.

summary(accidentData)
intervals <- c(0, 0.2, 0.4, 0.6, 0.8, 1)
accidentData$MORTALITAT_DIS <- cut(accidentData$MORTALITAT, breaks = intervals, labels = c("Lleu", "Moderat", "Considerable", "Greu","Molt Greu"), include.lowest = TRUE)

accidentData$MORTALITAT

```

```{r}

# fem una boxplot de totes les variables númeriques pero intentar buscar valors outliners que eliminiar

for (col in names(accidentData)) {
  if (is.numeric(accidentData[[col]])) {
    boxplot(accidentData[[col]], main = paste("Boxplot de", col))
  }
}



```
```{r}
# ara eliminarem algun dels outliners identificats, com el de les hores i els minuts, que estan per sobre dels valors possibles.

accidentData <- accidentData[accidentData$HOUR >= 0 & accidentData$HOUR <= 24, ]
accidentData <- accidentData[accidentData$MINUTE >= 0 & accidentData$MINUTE <= 60, ]

boxplot(accidentData$HOUR)
boxplot(accidentData$MINUTE)

```




```{r}

# representar unes quantes variables en histogrames per tenir una idea inicial dels valors de les variables
print(summary(accidentData))
hist(accidentData$VE_TOTAL,
     main = "Histograma dels vehicles implicats",
     col = "skyblue")
hist(accidentData$VE_FORMS,
     main = "Histograma dels vehicles motoritzats implicats",
     col = "skyblue")
hist(accidentData$FATALS,
     main = "Histograma dels vehicles motoritzats implicats",
     col = "skyblue")
```
```{r}
# Ara farem una primera aproximació a les dades per veure totes les correlacions entre totes les variables, fent servir la matriu de correlacions

# per mirar correlacions, només agafarem variables amb valors númerics
numeric_data <- accidentData[, sapply(accidentData, is.numeric)]

# també eliminarem la variable YEAR perqué en el càlcul de les correlacions no ens aporta res
numeric_data <- numeric_data[, -which(names(numeric_data) == 'YEAR')]

# càlcul de la matriu de correlació
correlation_matrix <- cor(numeric_data, use = "complete.obs")

# Valor absolut de la matriu, ja que no ens interesa si la correlació es positiva o negativa, només el valor absolut
absolute_correlation_matrix <- abs(correlation_matrix)

# intentem expresar la matriu de correlació de manera més gràfica utilitzaznt un mapa de calor
heatmap(correlation_matrix, 
        col = colorRampPalette(c("blue", "white", "red"))(100),
        symm = TRUE,
        margins = c(10, 10))

# ara analitzem amb més deteniment les variables més interessants i mirem amb quines altres variables estan més relacionades

# Comencem mirant la variable FATALS
correlations <- correlation_matrix["FATALS", ]
correlations <- correlations[order(-abs(correlations))]
print(paste("TOP 10", "FATALS", "son:"))
print(correlations[1:10])

# Veiem que per a la variable FATALS les tres variables més relacionades són el nombre de persones al vehicle, el nombre de persones implicades que no estàn al vehicle i els vehicles en circulació implicats. Com més persones i vehicles implicades més victimes mortals.

```
```{r}

# Mirem a quines hores hi ha més victimes mortals

FATALS_HOUR <- aggregate(FATALS ~ HOUR, accidentData, sum)
ggplot(FATALS_HOUR, aes(x = HOUR, y = FATALS)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Hora del dia", y = "Total de morts",
       title = "Reconte de persones per hora del dia") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 24))


# Ara mirem a quines hores hi ha més persones per vehicle per accident
PERSONS_HOUR <- aggregate(PERSONS ~ HOUR, accidentData, sum)
ggplot(PERSONS_HOUR, aes(x = HOUR, y = PERSONS)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Hora del dia", y = "Total de persones presents") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 24))
# Podem veure que la distribució respecte les víctimes mortals és molt semblat. Resultat esperat ja que són dos variables altament corralades


# Anem a veure a quines hores hi ha més persones sota els efectes del alcohol implicades
DRUNK_HOUR <- aggregate(DRUNK_DR ~ HOUR, accidentData, sum)
ggplot(DRUNK_HOUR, aes(x = HOUR, y = DRUNK_DR)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Hora del dia", y = "Total de persones sota els efectes del alcohol") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 24))

# Podem veure que la distribució és molt diferent a les altres dos. Resultat lógic, ja que és una variable molt menys correlada amb la variable FATALS


# Ara observem quin dia de la setmana hi ha més accidents
FATALS_DAY_WEEK <- aggregate(FATALS ~ DAY_WEEK, accidentData, sum)
ggplot(FATALS_DAY_WEEK, aes(x = DAY_WEEK, y = FATALS)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Dia de la setmana", y = "Total de personas mortes") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 7))

# Finalment observem quins dies de la setmana hi ha més afectats sota els efectes del alcohol
DRUNK_DAY_WEEK <- aggregate(DRUNK_DR ~ DAY_WEEK, accidentData, sum)
ggplot(DRUNK_DAY_WEEK, aes(x = DAY_WEEK, y = DRUNK_DR)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Dia de la setmana", y = "Total de persones sota els efectes del alcohol") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 7))



```

```{r}
# Ara procedirem a estudiar la variable creada anteriorment anomenada MORTALITAT, per intentar estudiar quins factors fan més mortals els accidents.

# Repetim el proces anterior
correlation_matrix <- cor(numeric_data, use = "complete.obs")

absolute_correlation_matrix <- abs(correlation_matrix)

heatmap(correlation_matrix, 
        col = colorRampPalette(c("blue", "white", "red"))(100),
        symm = TRUE,
        margins = c(10, 10))


correlations <- correlation_matrix["MORTALITAT", ]
correlations <- correlations[order(-abs(correlations))]
print(paste("TOP 10", "MORTALITAT", "son:"))
print(correlations[1:10])

cor(accidentData$FATALS, accidentData$MORTALITAT)
```

```{r}
# agafem ara les variables més corralades entre elles
llindar <- 0.18

correlaciones_filtradas <- correlation_matrix[correlation_matrix > llindar]

heatmap(correlation_matrix, 
        Colv = NA, 
        Rowv = NA, 
        col = colorRampPalette(c("blue", "white", "red"))(100), 
        main = "Heatmap de Correlación Filtrado")
```

```{r}
# Repetim els gràfiics fets anteriorment pero amb la variable MORTALITAT
MORTALITAT_HOUR <- aggregate(MORTALITAT ~ HOUR, accidentData, sum)
ggplot(MORTALITAT_HOUR, aes(x = HOUR, y = MORTALITAT)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Hora del dia", y = "Total de personas presentes",
       title = "Recuento de personas por hora del dia") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 24))

# La distribució és bastant semblant a la variable FATALS

# Fem el mateix amb el dia de la setmana
MORTALITAT_DAY_WEEK <- aggregate(MORTALITAT ~ DAY_WEEK, accidentData, sum)
ggplot(MORTALITAT_DAY_WEEK, aes(x = DAY_WEEK, y = MORTALITAT)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(x = "Hora del dia", y = "Total de personas presentes",
       title = "Recuento de personas por hora del dia") +
  theme_minimal()+
  coord_cartesian(xlim = c(0, 7))

# Tornem a tenir una distribució molt semblant

```



Les dades proporcionades estàn en bones condicions per ser analitzades, no hi ha molts valors nuls, tampoc hi ha molts outliners. No he vist la necesitat de normalitzar cap variable.

A l'hora de fer l'analisis, la conclusió més clara que es treu és que com a més persones involucrades més morts als accidents, i que els caps de setmana i per la tarda és on es produeixen més morts.

Davant aquesta premisa, he intentat mirar la relació entre morts i afectats a l'accident per intentar treure conclusions més precises i que no depenguin del número de persones implicades. El problema ha sigut que la nova variable creada estava completament correlada amb el nombre de persones, per aixo no ens ha aportat casi informació nova.

Seria necessari fer un estudi molt més exhaustiu per treure conclusions molt més clares.




